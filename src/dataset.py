import os
import cv2
import glob
import torch
import numpy as np
from torch.utils.data import Dataset
import albumentations as A
from albumentations.pytorch import ToTensorV2


class DeepFakeDataset(Dataset):
    def __init__(self, root_dir, mode='train', image_size=380):
        self.root_dir = root_dir
        self.mode = mode
        self.image_size = image_size
        self.image_paths = []
        self.labels = []

        # ë°ì´í„° ë¡œë“œ
        self._load_data()
        
        # ë³€í™˜
        self.transform = self._get_transforms()

    def _load_data(self):
        # 0: Real, 1: Fake
        class_map = {
            0: ['0_real', 'real', 'Real', 'REAL', '0'], 
            1: ['1_fake', 'fake', 'Fake', 'FAKE', '1']
        }

        print(f"[{self.mode.upper()}] ê²½ë¡œ íƒìƒ‰ ì‹œì‘: {os.path.abspath(self.root_dir)}")
        
        if not os.path.exists(self.root_dir):
            raise FileNotFoundError(f"í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {self.root_dir}")

        for label, folder_names in class_map.items():
            for folder_name in folder_names:
                target_path = os.path.join(self.root_dir, folder_name)
                
                if os.path.exists(target_path):
                    files = []
                    extensions = ['*.png', '*.PNG', '*.jpg', '*.JPG', '*.jpeg', '*.JPEG']
                    for ext in extensions:
                        found = glob.glob(os.path.join(target_path, "**", ext), recursive=True)
                        files.extend(found)
                    
                    if len(files) > 0:
                        self.image_paths.extend(files)
                        self.labels.extend([label] * len(files))
                        print(f"   '{folder_name}' í´ë”ì—ì„œ {len(files)}ì¥ ì°¾ìŒ! (Label: {label})")
                    else:
                        print(f"   '{folder_name}' í´ë”ëŠ” ìˆì§€ë§Œ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        if len(self.image_paths) == 0:
            print(f"'{self.root_dir}' ì•ˆì— ì´ë¯¸ì§€ê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
            raise ValueError(f"No images found in {self.root_dir}")

        print(f"ğŸ‰ [{self.mode.upper()}] ë¡œë“œ ì™„ë£Œ: ì´ {len(self.image_paths)}ì¥ ì¤€ë¹„ë¨.")

    def _get_transforms(self):
        if self.mode == 'train':
            return A.Compose([
                # í˜¹ì‹œ ëª°ë¼ì„œ inputê³¼ ê°™ì€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                # TODO: ì´í›„ì— í•˜ë“œì½”ë”© ì œê±°
                A.CenterCrop(self.image_size, self.image_size),
                
                # flip
                A.HorizontalFlip(p=0.5),
                
                # í”½ì…€ê°’ ë³€í™˜
                A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05, p=0.2),
                
                # ë‘ ê°œ ì¤‘ ëœë¤ noise ì¶”ê°€ (blur ëŒ€ì‹ )
                A.OneOf([
                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),
                    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.2),
                ], p=0.2),
                
                # ì •ê·œí™”
                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
                ToTensorV2()
            ])
        else:
            # ê²€ì¦
            return A.Compose([
                A.CenterCrop(self.image_size, self.image_size),
                A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
                ToTensorV2()
            ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        try:
            # ê²½ë¡œì— í•œê¸€ì´ ì„ì´ë©´ ì•ˆ ì½í˜€ì„œ imread ëŒ€ì‹  ì‚¬ìš©
            img_array = np.fromfile(img_path, np.uint8)
            image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            if image is None: raise Exception("Decode failed")
        except Exception:
            image = np.zeros((self.image_size, self.image_size, 3), dtype=np.uint8)
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ì •ì˜í•œ transform ì ìš©
        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']
            
        return image, torch.tensor(label, dtype=torch.long)
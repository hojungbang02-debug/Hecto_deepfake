import torch
import cv2
import os
import glob
import numpy as np
import csv
from tqdm import tqdm
from pathlib import Path
import albumentations as A
from albumentations.pytorch import ToTensorV2

# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
from src.model import DeepFakeModel

# ==========================================
# ì„¤ì •
# ==========================================
CONFIG = {
    'model_path': './model/best_model.pth',
    'test_dir': './test_data',               # í…ŒìŠ¤íŠ¸ ë°ì´í„° í´ë”
    'model_name': 'efficientnet_b4',
    'save_name': 'submission.csv',
    'device': 'cuda' if torch.cuda.is_available() else 'cpu'
}

# ì˜ˆì‹œ ì½”ë“œì˜ êµ¬ì¡°ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê²°ê³¼ ê°ì²´ í´ë˜ìŠ¤
class ProcessOutput:
    def __init__(self, filename, imgs=None, error=None):
        self.filename = filename  # íŒŒì¼ëª… (ì˜ˆ: video.mp4)
        self.imgs = imgs          # ì „ì²˜ë¦¬ëœ í…ì„œ (ì—†ìœ¼ë©´ None)
        self.error = error        # ì—ëŸ¬ ë©”ì‹œì§€ (ì—†ìœ¼ë©´ None)

# ==========================================
# í•¨ìˆ˜ ì •ì˜
# ==========================================

def get_transforms():
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì§• + ì •ê·œí™”)"""
    return A.Compose([
        A.Resize(224, 224),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ])

def preprocess_one(file_path, transform):
    """
    íŒŒì¼ í•˜ë‚˜ë¥¼ ì½ì–´ì„œ í…ì„œë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    - ì´ë¯¸ì§€: ê·¸ëŒ€ë¡œ ì½ìŒ
    - ë¹„ë””ì˜¤: ëœë¤ 5í”„ë ˆì„ ì¶”ì¶œ
    """
    filename = file_path.name
    str_path = str(file_path)
    
    try:
        # ë¹„ë””ì˜¤ì¸ ê²½ìš°
        if str_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):
            cap = cv2.VideoCapture(str_path)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if frame_count == 0:
                return ProcessOutput(filename, error="Empty Video")
            
            # ëœë¤ 5í”„ë ˆì„ ì¶”ì¶œ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì „ì²´)
            if frame_count > 5:
                indices = sorted(np.random.choice(frame_count, 5, replace=False))
            else:
                indices = range(frame_count)
                
            frames = []
            for i in indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                if ret:
                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    # Albumentations ì ìš©
                    frame = transform(image=frame)['image']
                    frames.append(frame)
            cap.release()
            
            if not frames:
                return ProcessOutput(filename, error="Read Fail")
            
            # [5, 3, 224, 224] í˜•íƒœë¡œ ìŠ¤íƒ
            imgs = torch.stack(frames)
            return ProcessOutput(filename, imgs=imgs)

        # ì´ë¯¸ì§€ì¸ ê²½ìš°
        else:
            image = cv2.imread(str_path)
            if image is None:
                return ProcessOutput(filename, error="Image Read Fail")
            
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = transform(image=image)['image']
            # [1, 3, 224, 224] (ë°°ì¹˜ ì°¨ì› ì¶”ê°€)
            imgs = image.unsqueeze(0)
            return ProcessOutput(filename, imgs=imgs)

    except Exception as e:
        return ProcessOutput(filename, error=str(e))

def infer_fake_probs(model, imgs, device):
    """
    ëª¨ë¸ì— ë„£ì–´ì„œ ê°€ì§œì¼ í™•ë¥ (0~1)ì„ ë±‰ì–´ì£¼ëŠ” í•¨ìˆ˜
    """
    with torch.no_grad():
        imgs = imgs.to(device)
        outputs = model(imgs)      # Logits
        probs = torch.sigmoid(outputs) # 0~1 í™•ë¥  ë³€í™˜
        
        # CPUë¡œ ê°€ì ¸ì™€ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        return probs.cpu().numpy().flatten().tolist()

# ==========================================
# ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    print(f"ğŸ”¥ ì¶”ë¡  ì‹œì‘! (Device: {CONFIG['device']})")
    
    # 1. ëª¨ë¸ ì¤€ë¹„
    model = DeepFakeModel(model_name=CONFIG['model_name'], pretrained=False).to(CONFIG['device'])
    
    if os.path.exists(CONFIG['model_path']):
        model.load_state_dict(torch.load(CONFIG['model_path']))
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    else:
        print("âŒ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! 0.5ë¡œ ì°ìŠµë‹ˆë‹¤.")
    
    model.eval()
    transform = get_transforms()

    # 2. íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (pathlib ì‚¬ìš© - ì˜ˆì‹œ ì½”ë“œ ìŠ¤íƒ€ì¼)
    TEST_DIR = Path(CONFIG['test_dir'])
    # ëª¨ë“  íŒŒì¼ ê°€ì ¸ì˜¤ê¸° (ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
    files = sorted([p for p in TEST_DIR.iterdir() if p.is_file() and p.name[0] != '.'])
    
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜: {len(files)}ê°œ")

    # 3. ë£¨í”„ ëŒë©´ì„œ ì¶”ë¡  (ì˜ˆì‹œ ì½”ë“œ ë¡œì§ ê·¸ëŒ€ë¡œ ì ìš©)
    results = {}
    
    for file_path in tqdm(files, desc="Processing"):
        # ì „ì²˜ë¦¬
        out = preprocess_one(file_path, transform)
        
        # Case 1: ì—ëŸ¬ ë°œìƒ (íŒŒì¼ ê¹¨ì§ ë“±) -> 0.5 (ëª¨ë¦„) ë˜ëŠ” 0.0 (Real) ì²˜ë¦¬
        if out.error:
            results[out.filename] = 0.5 # ì—ëŸ¬ë‚˜ë©´ ê·¸ëƒ¥ ë°˜ë°˜ í™•ë¥ ë¡œ ë˜ì§ (ì „ëµ)
        
        # Case 2: ì •ìƒ (ì´ë¯¸ì§€/ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆìŒ)
        elif out.imgs is not None:
            probs = infer_fake_probs(model, out.imgs, CONFIG['device'])
            # í™•ë¥ ë“¤ì˜ í‰ê· ì„ ì‚¬ìš© (ë¹„ë””ì˜¤ í”„ë ˆì„ì´ 5ê°œë©´ 5ê°œ í‰ê· )
            avg_prob = float(np.mean(probs))
            results[out.filename] = avg_prob
            
        # Case 3: ì´ìƒí•œ ê²½ìš°
        else:
            results[out.filename] = 0.5

    # 4. CSV ì €ì¥
    print(f"ğŸ’¾ '{CONFIG['save_name']}' ì €ì¥ ì¤‘...")
    
    with open(CONFIG['save_name'], 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['filename', 'prediction']) # í—¤ë” (ëŒ€íšŒ ê·œê²© í™•ì¸ í•„ìˆ˜!)
        
        for filename, prob in results.items():
            writer.writerow([filename, prob])
            
    print("ğŸ‰ Submission íŒŒì¼ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()